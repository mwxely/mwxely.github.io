---
permalink: /
title: ""
excerpt: "Homepage"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a second-year Ph.D. student with [Visual Intelligence Lab](https://sg-vilab.github.io/) at [Nanyang Technological University](https://www.ntu.edu.sg/), supervised by [Prof. Shijian Lu](https://personal.ntu.edu.sg/shijian.lu/). Prior to joining NTU, I obtained my B.S. degree in Computing Science from [University of Alberta](https://www.ualberta.ca/index.html). I also work closely with [Dr. Lidong Bing](https://lidongbing.github.io/) at [MiroMind AI](https://miromind.ai/) and [Dr. Song Bai](https://songbai.site/) at [ByteDance](https://www.bytedance.com/en/). My research interests lie broadly in the realms of video processing, spanning generation, understanding, reasoning, and agentic tool use.

Feel free to [reach out to me](https://drive.google.com/file/d/1ru6JmlBLg1KN7Ht2aOeUuhHty-f3R5w2/view?usp=sharing) for collaborations, questions, or just to chat!

üî• Exciting News
======
* 2025.06 - Two papers are accepted to ICCV 2025.
* 2025.05 - Two papers are accepted to ACL 2025.
* 2025.04 - Joined Shanda AI Research Institute as an AI Scientist Intern.
* 2023.11 - Joined ByteDance SG as a Research Intern.
* 2023.09 - One paper is accepted to NeurIPS 2023.
* 2023.01 - Joined Visual Intelligence Lab, NTU.

üìù Selected Publications ([Full List](https://mwxely.github.io/publications/))
======
[//]: # (----------- Preprint 2025 -------------------------)

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Preprint</div><img src='images/ToDRE.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[ToDRE: Visual Token Pruning via Diversity and Task Awareness for Efficient Large Vision-Language Models](https://arxiv.org/abs/2505.18757)

[//]: # (<strong><span class='show_paper_citations' data='ElujT6oAAAAJ:hqOjcs7Dif8C'></span></strong>)

Duo Li*, <u><b>Zuhao Yang*</b></u>, Shijian Lu

<i>Preprint 2025</i>

<a href="https://arxiv.org/pdf/2505.18757">paper</a> 
/ <a href="https://raw.githubusercontent.com/mwxely/mwxely.github.io/main/bibtex/li2025todre.html">bibtex</a>

</div>
</div>

[//]: # (----------- ICCV 2025 -------------------------)

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Preprint</div><img src='images/TE.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[TimeExpert: An Expert-Guided Video LLM for Video Temporal Grounding](https://arxiv.org/abs/2505.18757)

[//]: # (<strong><span class='show_paper_citations' data='ElujT6oAAAAJ:hqOjcs7Dif8C'></span></strong>)

<u><b>Zuhao Yang</b></u>, Yingchen Yu, Yunqing Zhao, Shijian Lu, Song Bai

<i>ICCV 2025</i>

<a href="https://arxiv.org/pdf/2505.18757">paper</a> 
/ <a href="https://raw.githubusercontent.com/mwxely/mwxely.github.io/main/bibtex/yang2025timeexpert.html">bibtex</a>
/ <a href="https://mwxely.github.io/projects/yang2025time/index">project page</a>

</div>
</div>

[//]: # (----------- ICCV 2025 -------------------------)

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Preprint</div><img src='images/VTG.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Versatile Transition Generation with Image-to-Video Diffusion](https://arxiv.org/abs/2505.18757)

[//]: # (<strong><span class='show_paper_citations' data='ElujT6oAAAAJ:hqOjcs7Dif8C'></span></strong>)

<u><b>Zuhao Yang</b></u>, Jiahui Zhang, Yingchen Yu, Shijian Lu, Song Bai

<i>ICCV 2025</i>

<a href="https://arxiv.org/pdf/2505.18757">paper</a> 
/ <a href="https://raw.githubusercontent.com/mwxely/mwxely.github.io/main/bibtex/yang2025versatile.html">bibtex</a>
/ <a href="https://mwxely.github.io/projects/yang2025vtg/index">project page</a>

</div>
</div>

[//]: # (----------- ACL 2025 -------------------------)

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACL</div><img src='images/QAEval.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[QAEval: Mixture of Evaluators for Question-Answering Task Evaluation](https://aclanthology.org/2025.acl-long.716/)

[//]: # (<strong><span class='show_paper_citations' data='ElujT6oAAAAJ:hqOjcs7Dif8C'></span></strong>)

Tan Yue, Rui Mao, Xuzhao Shi, Shuo Zhan, <u><b>Zuhao Yang</b></u>, Dongyan Zhao

<i>ACL 2025</i>

<a href="https://aclanthology.org/2025.acl-long.716.pdf">paper</a> 
/ <a href="https://raw.githubusercontent.com/mwxely/mwxely.github.io/main/bibtex/yue2025qaeval.html">bibtex</a>

</div>
</div>

[//]: # (----------- NeurIPS 2023 -------------------------)

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Preprint</div><img src='images/ToDRE.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[FACE: Evaluating Natural Language Generation with Fourier Analysis of Cross-Entropy](https://arxiv.org/abs/2305.10307)

[//]: # (<strong><span class='show_paper_citations' data='ElujT6oAAAAJ:hqOjcs7Dif8C'></span></strong>)

<u><b>Zuhao Yang*</b></u>, Yingfang Yuan*, Yang Xu*, Shuo Zhan, Huajun Bai, Kefan Chen

<i>NeurIPS 2023</i>

<a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/37094fdc81632915a5738293cf9b7ad4-Paper-Conference.pdf">paper</a> 
/ <a href="https://raw.githubusercontent.com/mwxely/mwxely.github.io/main/bibtex/yang2023face.html">bibtex</a>
/ <a href="https://github.com/CLCS-SUSTech/FACE">project page</a>

</div>
</div>

üìñ Educational Background
======
* 2024.01 - Present: Doctor of Philosophy, College of Computing and Data Science, Nanyang Technological University
* 2022.08 - 2024.01: Master in Artificial Intelligence, College of Computing and Data Science, Nanyang Technological University
* 2017.09 - 2021.06: Bachelor in Computing Science, Department of Computing Science, University of Alberta

üßë‚Äç‚öñÔ∏è Working Experiences
======
* 2025.04 - Present: AI Scientist Intern, Shanda AI Research Institute & MiroMind AI, Singapore
* 2023.11 - 2025.03: AI Research Intern, ByteDance Inc. & TikTok, Singapore
* 2021.05 - 2022.06: NLP Algorithm Engineer, TMI Robotics Technology, Shanghai

üíª Academic Services
=====
Conference Reviewer
* CVPR 24/25, ECCV 24, ACMMM 24, NeurIPS 24/25, ICLR 25, AISTATS 25, ICML 25, ICCV 25
Journal Reviewer
Pattern Recognition, Journal of Electronic Imaging
* Workshop PC Member
SyntaGen (CVPR 24/25), Neural Rendering Intelligence (CVPR 24), Agents That Help or Hinder? Rethinking Agentic AI in Real-World Workflows (AAAI 26)

üèÜ Patent & Awards
======
* Method, Device, and Medium for Video Temporal Grounding with Mixture-of-Experts, US Patent, 2024
* Method, Device, and Medium for Generating Transition Videos with Diffusion Model, SG Patent, 2024
* [Method, Device, and Medium for Automatic Question-Answering](http://epub.cnipa.gov.cn/patent/CN113946669A), CN Patent, 2022
* Outstanding Graduate, University of Alberta, 2021
* Dean's Honor Roll Award, University of Alberta, 2018 - 2020
* International Student Scholarship, University of Alberta, 2017 - 2019
