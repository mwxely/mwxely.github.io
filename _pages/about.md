---
permalink: /
title: ""
excerpt: "Homepage"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<style>
  .paper-box {
  display: flex;
  align-items: flex-start;
  margin-bottom: 24px;
  border-radius: 12px;
  box-shadow: 0 4px 16px 0 rgba(0,0,0,0.08);
  background: #fff;
  padding: 16px;
  gap: 20px;
}
.paper-box-image {
  flex: 0 0 160px;
  position: relative;
}
.paper-box-image .badge {
  position: absolute;
  left: 0; top: 0;
  background: #337ab7;
  color: #fff;
  padding: 2px 12px;
  font-size: 14px;
  border-radius: 8px 0 8px 0;
  font-weight: 700;
  z-index: 2;
}
.paper-box-image img {
  width: 100%;
  border-radius: 8px;
  margin-top: 22px;
}
.paper-box-text {
  flex: 1;
  font-size: 1.05em;
}
.paper-box-text a {
  color: #1684fc;
  font-weight: 600;
}
.paper-box-text i {
  color: #555;
  font-style: italic;
}
</style>

I am a second-year Ph.D. student with [Visual Intelligence Lab](https://sg-vilab.github.io/) at [Nanyang Technological University](https://www.ntu.edu.sg/), supervised by [Prof. Shijian Lu](https://personal.ntu.edu.sg/shijian.lu/). Prior to joining NTU, I obtained my B.S. degree in Computing Science from [University of Alberta](https://www.ualberta.ca/index.html). I also work closely with [Dr. Lidong Bing](https://lidongbing.github.io/) at [MiroMind AI](https://miromind.ai/) and [Dr. Song Bai](https://songbai.site/) at [ByteDance](https://www.bytedance.com/en/). My research interests lie broadly in the realms of video processing, spanning generation, understanding, reasoning, and agentic tool use.

Feel free to [reach out to me](https://drive.google.com/file/d/1ru6JmlBLg1KN7Ht2aOeUuhHty-f3R5w2/view?usp=sharing) for collaborations, questions, or just to chat!

ğŸ”¥ Exciting News
---
* 2025.06 - Two papers are accepted to ICCV 2025.
* 2025.05 - Two papers are accepted to ACL 2025.
* 2025.04 - Joined Shanda AI Research Institute as an AI Scientist Intern.
* 2023.11 - Joined ByteDance SG as a Research Intern.
* 2023.09 - One paper is accepted to NeurIPS 2023.
* 2023.01 - Joined Visual Intelligence Lab, NTU.


ğŸ“ Selected Publications ([Full List](https://mwxely.github.io/publications/))
---
<div class="paper-box">
  <div class="paper-box-image">
    <span class="badge">Preprint</span>
    <img src="images/ToDRE.png" alt="ToDRE" width="100%">
  </div>
  <div class="paper-box-text">
    <a href="https://arxiv.org/abs/2505.18757"><b>ToDRE: Visual Token Pruning via Diversity and Task Awareness for Efficient Large Vision-Language Models</b></a><br>
    Duo Li*, <u><b>Zuhao Yang*</b></u>, Shijian Lu<br>
    <i>PreprintÂ 2025</i><br>
    <a href="https://arxiv.org/pdf/2505.18757">paper</a>Â /Â <a href="https://mwxely.github.io/bibtex/li2025todre.html">bibtex</a>
  </div>
</div>

<div class="paper-box">
  <div class="paper-box-image">
    <span class="badge">ICCV</span>
    <img src="images/TE.png" alt="TimeExpert" width="100%">
  </div>
  <div class="paper-box-text">
    <a href="https://arxiv.org/abs/2505.18757"><b>TimeExpert: An Expert-Guided Video LLM for Video Temporal Grounding</b></a><br>
    <u><b>Zuhao Yang</b></u>, Yingchen Yu, Yunqing Zhao, Shijian Lu, Song Bai<br>
    <i>ICCVÂ 2025</i><br>
    <a href="https://arxiv.org/pdf/2505.18757">paper</a>Â /Â <a href="https://mwxely.github.io/bibtex/yang2025timeexpert.html">bibtex</a>Â /Â <a href="https://mwxely.github.io/projects/yang2025time/index">project page</a>
  </div>
</div>

<div class="paper-box">
  <div class="paper-box-image">
    <span class="badge">ICCV</span>
    <img src="images/VTG.png" alt="VTG" width="100%">
  </div>
  <div class="paper-box-text">
    <a href="https://arxiv.org/abs/2505.18757"><b>Versatile Transition Generation with Image-to-Video Diffusion</b></a><br>
    <u><b>Zuhao Yang</b></u>, Jiahui Zhang, Yingchen Yu, Shijian Lu, Song Bai<br>
    <i>ICCVÂ 2025</i><br>
    <a href="https://arxiv.org/pdf/2505.18757">paper</a>Â /Â <a href="https://mwxely.github.io/bibtex/yang2025versatile.html">bibtex</a>Â /Â <a href="https://mwxely.github.io/projects/yang2025vtg/index">project page</a>
  </div>
</div>

<div class="paper-box">
  <div class="paper-box-image">
    <span class="badge">ACL</span>
    <img src="images/QAEval.png" alt="QAEval" width="100%">
  </div>
  <div class="paper-box-text">
    <a href="https://aclanthology.org/2025.acl-long.716/"><b>QAEval: Mixture of Evaluators for Questionâ€‘Answering Task Evaluation</b></a><br>
    Tan Yue, Rui Mao, Xuzhao Shi, Shuo Zhan, <u><b>Zuhao Yang</b></u>, Dongyan Zhao<br>
    <i>ACLÂ 2025</i><br>
    <a href="https://aclanthology.org/2025.acl-long.716.pdf">paper</a>Â /Â <a href="https://mwxely.github.io/bibtex/yue2025qaeval.html">bibtex</a>
  </div>
</div>

<div class="paper-box">
  <div class="paper-box-image">
    <span class="badge">NeurIPS</span>
    <img src="images/FACE.png" alt="FACE" width="100%">
  </div>
  <div class="paper-box-text">
    <a href="https://arxiv.org/abs/2305.10307"><b>FACE: Evaluating Natural Language Generation with Fourier Analysis of Crossâ€‘Entropy</b></a><br>
    <u><b>Zuhao Yang*</b></u>, Yingfang Yuan*, Yang Xu*, Shuo Zhan, Huajun Bai, Kefan Chen<br>
    <i>NeurIPSÂ 2023</i><br>
    <a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/37094fdc81632915a5738293cf9b7ad4-Paper-Conference.pdf">paper</a>Â /Â <a href="https://mwxely.github.io/bibtex/yang2023face.html">bibtex</a>Â /Â <a href="https://github.com/CLCS-SUSTech/FACE">project page</a>
  </div>
</div>

ğŸ“– Educational Background
---
* 2024.01 - Present: Doctor of Philosophy, College of Computing and Data Science, Nanyang Technological University
* 2022.08 - 2024.01: Master in Artificial Intelligence, College of Computing and Data Science, Nanyang Technological University
* 2017.09 - 2021.06: Bachelor in Computing Science, Department of Computing Science, University of Alberta

ğŸ§‘â€âš–ï¸ Working Experiences
---
* 2025.04 - Present: AI Scientist Intern, Shanda AI Research Institute & MiroMind AI, Singapore
* 2023.11 - 2025.03: AI Research Intern, ByteDance Inc. & TikTok, Singapore
* 2021.05 - 2022.06: NLP Algorithm Engineer, TMI Robotics Technology, Shanghai

ğŸ’» Academic Services
---
**Conference Reviewer**
* CVPR 24/25, ECCV 24, ACMMM 24, NeurIPS 24/25, ICLR 25, AISTATS 25, ICML 25, ICCV 25  

**Journal Reviewer**
* Pattern Recognition, Journal of Electronic Imaging  

**Workshop PC Member**
* SyntaGen (CVPR 24/25), Neural Rendering Intelligence (CVPR 24), Agents That Help or Hinder? Rethinking Agentic AI in Real-World Workflows (AAAI 26)


ğŸ† Patent & Awards
---
* Method, Device, and Medium for Video Temporal Grounding with Mixture-of-Experts, US Patent, 2024
* Method, Device, and Medium for Generating Transition Videos with Diffusion Model, SG Patent, 2024
* [Method, Device, and Medium for Automatic Question-Answering](http://epub.cnipa.gov.cn/patent/CN113946669A), CN Patent, 2022
* Outstanding Graduate, University of Alberta, 2021
* Dean's Honor Roll Award, University of Alberta, 2018 - 2020
* International Student Scholarship, University of Alberta, 2017 - 2019
